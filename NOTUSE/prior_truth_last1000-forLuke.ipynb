{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi Luke! Things you will have to change in this notebook:\n",
    "\n",
    "1. PATH variables in next cell\n",
    "2. Change lmr_names and model_names to reflect all the additional models\n",
    "3. Make new config files corresponding to each prior and put them in the CFGPATH directory. As you'll see below, I set these to be of format config.yml.superprior.lmr_names\\[i\\] so e.g. when I was using CCSM4 LM, config.yml.superprior.ccsm4_last_millenium.\n",
    "\n",
    "After that, once you get all the modules loaded (using the lmr_py3 environment), I think it should be good to go to compute pseudoproxy experiments for arbitrary combinations of model priors (including superpriors).\n",
    "\n",
    "As I recall, the parallel computation takes ~1 day for the 3x3 problem on 8 cores.\n",
    "\n",
    "I have lots of plotting routines that make use of the resulting dictionary of sister experiments that I'm happy to send along later once I comment them :-p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luke: define system-specific file paths here\n",
    "\n",
    "CFGPATH  = ''\n",
    "SAVEPATH = ''\n",
    "LMRPATH  = ''\n",
    "\n",
    "# Define an array of prior model names used in file names and config files.\n",
    "# Examples are what I used.\n",
    "lmr_names = ['ccsm4_last_millenium',\n",
    "             'mpi-esm-p_last_millenium',\n",
    "             'hadcm3_last_millenium']\n",
    "\n",
    "# Helpful to have a human readable list for plotting etc.\n",
    "model_names = ['CCSM4','MPI-ESM','HadCM3']\n",
    "\n",
    "# In principle, shouldn't have to change anything after this. In practice..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules. Might not all be needed for now but eventually\n",
    "# will for plotting.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import LMR_lite_utils as LMRlite\n",
    "import LMR_utils\n",
    "import LMR_config\n",
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature\n",
    "from cartopy.util import add_cyclic_point\n",
    "%matplotlib inline\n",
    "import cartopy.util as cutil\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "sys.path.append(LMRPATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load proxies to use their locations\n",
    "\n",
    "# Load a config file to use in processing data.\n",
    "cfile = CFGPATH+'/config.yml.superprior.'+lmr_names[0]\n",
    "yaml_file = os.path.join(LMR_config.SRC_DIR,cfile)\n",
    "cfg = LMRlite.load_config(yaml_file)\n",
    "\n",
    "# Load proxies\n",
    "prox_manager = LMRlite.load_proxies(cfg)\n",
    "numprox = len(prox_manager.all_proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and interpolate all of the priors I want to use as truth.\n",
    "# This should be readily scalable to an arbitrary number of models.\n",
    "\n",
    "# Initialize a single array of all of the interpolated model fields.\n",
    "# Facilitates doing things with for loops later, so this array gets used a lot!\n",
    "ad = []\n",
    "\n",
    "for ii in np.arange(len(lmr_names)):\n",
    "    \n",
    "    # Define a dictionary of model attributes that will be populated here\n",
    "    # and then appended to ad\n",
    "    dd = {}\n",
    "\n",
    "    # Get the config file set\n",
    "    cfile = CFGPATH+'/config.yml.superprior.'+lmr_names[ii]\n",
    "    yaml_file = os.path.join(LMR_config.SRC_DIR,cfile)\n",
    "    cfg = LMRlite.load_config(yaml_file)\n",
    "    \n",
    "    # Load the prior\n",
    "    X, Xb_one = LMRlite.load_prior(cfg)\n",
    "\n",
    "    # check if config is set to regrid the prior. We're regridding everything to 20c\n",
    "    if cfg.prior.regrid_method:\n",
    "        print('regridding prior...')\n",
    "        # this function over-writes X, even if return is given a different name\n",
    "        [X,Xb_one_new] = LMRlite.prior_regrid(cfg,X,Xb_one,verbose=False)\n",
    "    else:\n",
    "        X.trunc_state_info = X.full_state_info\n",
    "    \n",
    "    Xb_one = Xb_one_new\n",
    "    \n",
    "    # Compute Xb prime, residual from the mean\n",
    "    Xbp = Xb_one - Xb_one.mean(axis=1,keepdims=True)\n",
    "    grid = LMRlite.Grid(X)    \n",
    "\n",
    "    # populate the dictionary for this particular model\n",
    "    dd['X']        = X\n",
    "    dd['Xbp']      = Xbp\n",
    "    dd['name']     = model_names[ii]\n",
    "    dd['lmr_name'] = lmr_names[ii]\n",
    "    dd['grid']     = grid\n",
    "\n",
    "    print(ii)\n",
    "    print(dd['name'])\n",
    "\n",
    "    ad.append(dd)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some routines (modified from LMR code) to compute \n",
    "# pseudoproxies and y_es\n",
    "\n",
    "def mk_pproxies(X,Xbp,prox_manager,SNR,grid):\n",
    "\n",
    "    \"\"\"\n",
    "    Construct pseudoproxies \n",
    "    \"\"\"\n",
    "\n",
    "    numprox = len(prox_manager.ind_assim)\n",
    "    vY = np.zeros([numprox,grid.nens])\n",
    "    vR = []\n",
    "    vP = []\n",
    "\n",
    "    for proxy_idx, Y in enumerate(prox_manager.sites_assim_proxy_objs()):\n",
    "\n",
    "        # Get grid indices\n",
    "        tmp = grid.lat[:,0]-Y.lat\n",
    "        itlat = np.argmin(np.abs(tmp))\n",
    "        tmp = grid.lon[0,:]-Y.lon\n",
    "        itlon = np.argmin(np.abs(tmp))\n",
    "        npos = itlat*grid.nlon + itlon\n",
    "\n",
    "        # Noise amplitude corresponding to SNR by stdev\n",
    "        sig = np.std(Xbp[npos,:])\n",
    "\n",
    "        # Make pproxies\n",
    "        vY[proxy_idx,:] = Xbp[npos,:] + np.random.randn(grid.nens,)*sig/SNR\n",
    "        vR.append((sig/SNR)**2)\n",
    "        vP.append(proxy_idx)\n",
    "\n",
    "    return vY, vR, vP\n",
    "\n",
    "def mk_yes(X,Xbp,prox_manager,grid):\n",
    "\n",
    "    \"\"\"\n",
    "    Construct yes\n",
    "    \"\"\"\n",
    "\n",
    "    vYe = np.zeros([numprox,grid.nens])\n",
    "    vYe_coords = np.zeros([numprox,2])\n",
    "\n",
    "    for proxy_idx, Y in enumerate(prox_manager.sites_assim_proxy_objs()):\n",
    "\n",
    "        # Get grid indices\n",
    "        tmp = grid.lat[:,0]-Y.lat\n",
    "        itlat = np.argmin(np.abs(tmp))\n",
    "        tmp = grid.lon[0,:]-Y.lon\n",
    "        itlon = np.argmin(np.abs(tmp))\n",
    "        npos = itlat*grid.nlon + itlon\n",
    "        \n",
    "        # The ensemble prior estimates\n",
    "        vYe[proxy_idx,:] = Xbp[npos,:]\n",
    "        vYe_coords[proxy_idx,:] = X.coords[npos,:]\n",
    "\n",
    "    return vYe, vYe_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define a function to compare what happens for various truth-prior pairs.\n",
    "# This is what does the heavy lifting! Made it a function so that it can be \n",
    "# run in parallel below as a function of LOCRAD and SNR.\n",
    "\n",
    "def process_input(LOCRAD,SNR):\n",
    "\n",
    "    NENS = grid.nens\n",
    "\n",
    "    # Initialize array of dictionaries containing the different comparisons\n",
    "    cdd = []\n",
    "\n",
    "    # Loop over prior files\n",
    "    for ii in np.arange(len(lmr_names)):\n",
    "\n",
    "        # Load the config file corresponding to the iith prior\n",
    "        cfile = './configs/config.yml.nullspace.'+lmr_names[ii]\n",
    "        yaml_file = os.path.join(LMR_config.SRC_DIR,cfile)\n",
    "        cfg = LMRlite.load_config(yaml_file)\n",
    "\n",
    "        # Compute effective observations\n",
    "        vYe, vYe_coords = mk_yes(ad[ii]['X'],ad[ii]['Xbp'],prox_manager,ad[ii]['grid'])\n",
    "\n",
    "        # change the localization radius in the config file\n",
    "        cfg_params = LMR_utils.param_cfg_update('core.loc_rad',LOCRAD)\n",
    "        cfg_new = LMR_config.Config(**cfg_params)\n",
    "\n",
    "        # Loop over truth files\n",
    "        for jj in np.arange(len(lmr_names)):\n",
    "\n",
    "            # Make pseudoproxies\n",
    "            vY, vR, vP = mk_pproxies(ad[jj]['X'],ad[jj]['Xbp'],prox_manager,SNR,ad[jj]['grid'])\n",
    "\n",
    "            fp = np.empty([ad[ii]['grid'].nlon*ad[ii]['grid'].nlat,NENS])\n",
    "\n",
    "            # Loop over ensemble members in truth. f are the reconstructions.\n",
    "            # Use the fast solver if not localizing.\n",
    "            for kk in np.arange(NENS):\n",
    "\n",
    "                if LOCRAD==0.:\n",
    "                    f,Xa,_ = LMRlite.Kalman_optimal(vY[:,kk],vR,vYe,ad[ii]['Xbp'],verbose=False)\n",
    "                else:\n",
    "                    f,Xa = LMRlite.Kalman_ESRF(cfg_new,vY[:,kk],vR,vYe,ad[ii]['Xbp'],X=ad[ii]['X'],vYe_coords=vYe_coords,verbose=False)\n",
    "\n",
    "                xam = Xa.mean(axis=1)\n",
    "                Xap = np.subtract(Xa,xam[:,None])\n",
    "                fp[:,kk]    = f\n",
    "\n",
    "            # Store information in a dictionary for this prior-truth pair\n",
    "            c = {}\n",
    "            c['locrad']     = LOCRAD\n",
    "            c['snr']        = SNR\n",
    "            c['prior_name'] = ad[ii]['name']\n",
    "            c['truth_name'] = ad[jj]['name']\n",
    "            c['pind']       = ii\n",
    "            c['tind']       = jj\n",
    "            c['recon']      = fp\n",
    "            c['rmse']       = np.mean((ad[jj]['Xbp'][:,:NENS]-fp)**2,1)**.5\n",
    "            c['Xa']         = Xa\n",
    "\n",
    "\n",
    "            # Concatenate the dictionary to a list corresponding to all prior-truth pairs \n",
    "            # for the choices of LOCRAD and SNR\n",
    "            cdd.append(c)\n",
    "\n",
    "    # Save all prior-truth pairs for these choices of LOCRAD and SNR\n",
    "    print('saving for LOCRAD = '+ str(LOCRAD) + ' and SNR = '+ str(SNR))\n",
    "    np.save(SAVEPATH+'/superprior_locrad_' + str(LOCRAD)+ '_snr_' + str(SNR),cdd)\n",
    "print('Done!')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in parallel\n",
    "SNR = 0.4\n",
    "LOCRADs = [0.,5000.,10000.,25000.]\n",
    "nj = len(LOCRADs)\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "Parallel(n_jobs=nj)(delayed(process_input)(LOCRADs[i],SNR) for i in np.arange(nj))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
