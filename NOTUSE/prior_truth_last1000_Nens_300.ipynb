{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs 300-member experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the directory path to your LMR repository here\n",
    "import sys\n",
    "sys.path.append(\"/Users/dan/Desktop/LMR_py3/\")\n",
    "#!cd /Users/dan/Desktop/LMR_py3\n",
    "\n",
    "# prefix for figure filename\n",
    "#fig_prefix='prior_truth_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading information from datasets.yml\n",
      "Loading information from grid_def.yml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/Users/dan/Desktop/LMR_py3')\n",
    "import LMR_lite_utils as LMRlite\n",
    "import LMR_utils\n",
    "import LMR_config\n",
    "import numpy as np\n",
    "import os,sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature\n",
    "from cartopy.util import add_cyclic_point\n",
    "%matplotlib inline\n",
    "import cartopy.util as cutil\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking configuration ... \n",
      "OK!\n",
      "                                 Bivalve_d18O :     1\n",
      "               Corals and Sclerosponges_Rates :     8\n",
      "                Corals and Sclerosponges_SrCa :    25\n",
      "                Corals and Sclerosponges_d18O :    59\n",
      "                        Ice Cores_MeltFeature :     1\n",
      "                               Ice Cores_d18O :    28\n",
      "                                 Ice Cores_dD :     7\n",
      "                              Lake Cores_Misc :     2\n",
      "                             Lake Cores_Varve :     5\n",
      "                       Tree Rings_WidthPages2 :   347\n",
      "                       Tree Rings_WoodDensity :    59\n",
      "                                        TOTAL :   542\n",
      "-----------------------------------------------------\n",
      "completed in 13.91474199295044 seconds\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# load proxies\n",
    "lmr_names = ['ccsm4_last_millenium.300',\n",
    "             'mpi-esm-p_last_millenium.300',\n",
    "             'hadcm3_last_millenium.300']\n",
    "cfile = './configs/config.yml.nullspace.'+lmr_names[0]\n",
    "yaml_file = os.path.join(LMR_config.SRC_DIR,cfile)\n",
    "cfg = LMRlite.load_config(yaml_file)\n",
    "\n",
    "prox_manager = LMRlite.load_proxies(cfg)\n",
    "numprox = len(prox_manager.all_proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking configuration ... \n",
      "OK!\n",
      "Reading file:  /Users/dan/Desktop/LMR_py3/data/model/ccsm4_last_millenium/tas_sfc_Amon_CCSM4_past1000_085001-185012.nc\n",
      "(12012, 192, 288)\n",
      "indlat= 0  indlon= 1\n",
      "Anomalies provided as the prior: Removing the temporal mean (for every gridpoint)...\n",
      "tas : Global(monthly): mean= 8.072375e-07  , std-dev= 1.8899411\n",
      "Averaging over month sequence: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "tas : Global(time-averaged): mean= 4.4424884352419226e-08  , std-dev= 0.8317386411161235\n",
      " \n",
      "State vector information:\n",
      "Nx = 55296\n",
      "state_vect_info= {'tas_sfc_Amon': {'pos': (0, 55295), 'spacecoords': ('lat', 'lon'), 'spacedims': (192, 288), 'vartype': '2D:horizontal'}}\n",
      "Random selection of 300 ensemble members\n",
      "regridding prior...\n",
      "0 55295\n",
      "(55296, 300)\n",
      "(55296, 2)\n",
      "(55296, 2)\n",
      "tas_sfc_Amon  : 2D lat/lon variable, truncating this variable\n",
      "nlat,nlon: 192 288\n",
      "=> Full array:      -9.229859352111816 8.779441833496094 0.0038393562513812877 0.831769751944296\n",
      "=> Truncated array: -9.0365372796429 8.587566246732372 0.00389542897224295 0.8271144363830388\n",
      "0\n",
      "CCSM4\n",
      "Checking configuration ... \n",
      "OK!\n",
      "Reading file:  /Users/dan/Desktop/LMR_py3/data/model/mpi-esm-p_last_millenium/tas_sfc_Amon_MPI-ESM-P_past1000_085001-185012.nc\n",
      "(12000, 96, 192)\n",
      "indlat= 0  indlon= 1\n",
      "Anomalies provided as the prior: Removing the temporal mean (for every gridpoint)...\n",
      "tas : Global(monthly): mean= 9.960508e-06  , std-dev= 1.6648952\n",
      "Averaging over month sequence: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "tas : Global(time-averaged): mean= 1.000328960082861e-05  , std-dev= 0.7613386358533724\n",
      " \n",
      "State vector information:\n",
      "Nx = 18432\n",
      "state_vect_info= {'tas_sfc_Amon': {'pos': (0, 18431), 'spacecoords': ('lat', 'lon'), 'spacedims': (96, 192), 'vartype': '2D:horizontal'}}\n",
      "Random selection of 300 ensemble members\n",
      "regridding prior...\n",
      "0 18431\n",
      "(18432, 300)\n",
      "(18432, 2)\n",
      "(18432, 2)\n",
      "tas_sfc_Amon  : 2D lat/lon variable, truncating this variable\n",
      "nlat,nlon: 96 192\n",
      "=> Full array:      -9.772396087646484 8.47607707977295 -0.005387212000712712 0.7617626502950686\n",
      "=> Truncated array: -9.66048160820951 8.147501329465374 -0.005392486824011456 0.7519879456291672\n",
      "1\n",
      "MPI-ESM\n",
      "Checking configuration ... \n",
      "OK!\n",
      "Reading file:  /Users/dan/Desktop/LMR_py3/data/model/hadcm3_last_millenium/tas_sfc_Amon_HadCM3_past1000_085001-185012.nc\n",
      "(12012, 73, 96)\n",
      "indlat= 0  indlon= 1\n",
      "Anomalies provided as the prior: Removing the temporal mean (for every gridpoint)...\n",
      "tas : Global(monthly): mean= -3.075072e-07  , std-dev= 1.996391\n",
      "Averaging over month sequence: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "tas : Global(time-averaged): mean= -2.700413205941557e-07  , std-dev= 0.8439147355739832\n",
      " \n",
      "State vector information:\n",
      "Nx = 7008\n",
      "state_vect_info= {'tas_sfc_Amon': {'pos': (0, 7007), 'spacecoords': ('lat', 'lon'), 'spacedims': (73, 96), 'vartype': '2D:horizontal'}}\n",
      "Random selection of 300 ensemble members\n",
      "regridding prior...\n",
      "0 7007\n",
      "(7008, 300)\n",
      "(7008, 2)\n",
      "(7008, 2)\n",
      "tas_sfc_Amon  : 2D lat/lon variable, truncating this variable\n",
      "nlat,nlon: 73 96\n",
      "=> Full array:      -12.578052520751953 9.844019889831543 -0.0021794164117026026 0.8386386072159231\n",
      "=> Truncated array: -12.237434665633547 9.082909711367645 -0.0018747949538433428 0.8039684456924491\n",
      "2\n",
      "HadCM3\n"
     ]
    }
   ],
   "source": [
    "# Load and interpolate all of the priors I want to use as truth\n",
    "\n",
    "lmr_names = ['ccsm4_last_millenium.300',\n",
    "             'mpi-esm-p_last_millenium.300',\n",
    "             'hadcm3_last_millenium.300']\n",
    "model_names = ['CCSM4','MPI-ESM','HadCM3']\n",
    "\n",
    "# Initialize an array of various interpolated model fields\n",
    "ad = []\n",
    "\n",
    "for ii in np.arange(len(lmr_names)):\n",
    "    dd = {}\n",
    "    cfile = './configs/config.yml.nullspace.'+lmr_names[ii]\n",
    "    yaml_file = os.path.join(LMR_config.SRC_DIR,cfile)\n",
    "    cfg = LMRlite.load_config(yaml_file)\n",
    "    \n",
    "    X, Xb_one = LMRlite.load_prior(cfg)\n",
    "    Xbp = Xb_one - Xb_one.mean(axis=1,keepdims=True)\n",
    "    \n",
    "    # check if config is set to regrid the prior\n",
    "    if cfg.prior.regrid_method:\n",
    "        print('regridding prior...')\n",
    "        # this function over-writes X, even if return is given a different name\n",
    "        [X,Xb_one_new] = LMRlite.prior_regrid(cfg,X,Xb_one,verbose=False)\n",
    "    else:\n",
    "        X.trunc_state_info = X.full_state_info\n",
    "    \n",
    "    Xb_one = Xb_one_new\n",
    "    Xbp = Xb_one - Xb_one.mean(axis=1,keepdims=True)\n",
    "    grid = LMRlite.Grid(X)    \n",
    "    \n",
    "    dd['X']        = X\n",
    "    dd['Xbp']      = Xbp\n",
    "    dd['name']     = model_names[ii]\n",
    "    dd['lmr_name'] = lmr_names[ii]\n",
    "    dd['grid']     = grid\n",
    "\n",
    "    print(ii)\n",
    "    print(dd['name'])\n",
    "\n",
    "    ad.append(dd)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_pproxies(X,Xbp,prox_manager,SNR,grid):\n",
    "\n",
    "    \"\"\"\n",
    "    Construct pseudoproxies \n",
    "    \"\"\"\n",
    "\n",
    "    numprox = len(prox_manager.ind_assim)\n",
    "\n",
    "    vY = np.zeros([numprox,grid.nens])\n",
    "    vR = []\n",
    "    vP = []\n",
    "\n",
    "    for proxy_idx, Y in enumerate(prox_manager.sites_assim_proxy_objs()):\n",
    "        # get grid indices\n",
    "        tmp = grid.lat[:,0]-Y.lat\n",
    "        itlat = np.argmin(np.abs(tmp))\n",
    "        tmp = grid.lon[0,:]-Y.lon\n",
    "        itlon = np.argmin(np.abs(tmp))\n",
    "        npos = itlat*grid.nlon + itlon\n",
    "\n",
    "        # Noise amplitude corresponding to SNR by stdev\n",
    "        sig = np.std(Xbp[npos,:])\n",
    "        #print(sig)\n",
    "        #print(sig/SNR)\n",
    "        # Make pproxies\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        vY[proxy_idx,:] = Xbp[npos,:] + np.random.randn(grid.nens,)*sig/SNR\n",
    "        vR.append((sig/SNR)**2)\n",
    "        vP.append(proxy_idx)\n",
    "\n",
    "    return vY, vR, vP\n",
    "\n",
    "def mk_yes(X,Xbp,prox_manager,grid):\n",
    "\n",
    "    vYe = np.zeros([numprox,grid.nens])\n",
    "    vYe_coords = np.zeros([numprox,2])\n",
    "\n",
    "    for proxy_idx, Y in enumerate(prox_manager.sites_assim_proxy_objs()):\n",
    "        # get grid indices\n",
    "        tmp = grid.lat[:,0]-Y.lat\n",
    "        itlat = np.argmin(np.abs(tmp))\n",
    "        tmp = grid.lon[0,:]-Y.lon\n",
    "        itlon = np.argmin(np.abs(tmp))\n",
    "        npos = itlat*grid.nlon + itlon\n",
    "        # the ensemble prior estimates\n",
    "        vYe[proxy_idx,:] = Xbp[npos,:]\n",
    "        vYe_coords[proxy_idx,:] = X.coords[npos,:]\n",
    "\n",
    "    return vYe, vYe_coords\n",
    "\n",
    "def mk_yes2(X,Xbp,prox_manager,grid):\n",
    "\n",
    "    vYe = np.zeros([numprox,grid.nens])\n",
    "    vYe_coords = np.zeros([numprox,2])\n",
    "    nposv = np.empty(numprox)\n",
    "\n",
    "    for proxy_idx, Y in enumerate(prox_manager.sites_assim_proxy_objs()):\n",
    "        # get grid indices\n",
    "        tmp = grid.lat[:,0]-Y.lat\n",
    "        itlat = np.argmin(np.abs(tmp))\n",
    "        tmp = grid.lon[0,:]-Y.lon\n",
    "        itlon = np.argmin(np.abs(tmp))\n",
    "        npos = itlat*grid.nlon + itlon\n",
    "        # the ensemble prior estimates\n",
    "        vYe[proxy_idx,:] = Xbp[npos,:]\n",
    "        vYe_coords[proxy_idx,:] = X.coords[npos,:]\n",
    "        nposv[proxy_idx] = int(npos)\n",
    "\n",
    "    return vYe, vYe_coords, nposv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Compare what happens for various truth-prior pairs\n",
    "# Things to include: localization, SNR, ob network\n",
    "\n",
    "def process_input(LOCRAD):\n",
    "\n",
    "    SNR = 0.4\n",
    "    NENS = grid.nens\n",
    "    # for testing\n",
    "    # NENS = 2\n",
    "\n",
    "    # Initialize array of dictionaries containing the different comparisons\n",
    "    cdd = []\n",
    "\n",
    "    # Loop over prior files\n",
    "    for ii in np.arange(len(lmr_names)):\n",
    "\n",
    "        # Load the config file corresponding to the iith prior\n",
    "        cfile = './configs/config.yml.nullspace.'+lmr_names[ii]\n",
    "        yaml_file = os.path.join(LMR_config.SRC_DIR,cfile)\n",
    "        cfg = LMRlite.load_config(yaml_file)\n",
    "\n",
    "        # Compute effective observations\n",
    "        vYe, vYe_coords = mk_yes(ad[ii]['X'],ad[ii]['Xbp'],prox_manager,ad[ii]['grid'])\n",
    "\n",
    "        # change the localization radius in the config file\n",
    "        cfg_params = LMR_utils.param_cfg_update('core.loc_rad',LOCRAD)\n",
    "        cfg_new = LMR_config.Config(**cfg_params)\n",
    "\n",
    "        # Loop over truth files\n",
    "        for jj in np.arange(len(lmr_names)):\n",
    "\n",
    "            # Use a precomputed interpolated version of the truth\n",
    "            vY, vR, vP = mk_pproxies(ad[jj]['X'],ad[jj]['Xbp'],prox_manager,SNR,ad[jj]['grid'])\n",
    "\n",
    "            fp = np.empty([ad[ii]['grid'].nlon*ad[ii]['grid'].nlat,NENS])\n",
    "\n",
    "            # Loop over ensemble members in truth. f are the reconstructions.\n",
    "            for kk in np.arange(NENS):\n",
    "\n",
    "                if LOCRAD==0.:\n",
    "                    f,Xa,_ = LMRlite.Kalman_optimal(vY[:,kk],vR,vYe,ad[ii]['Xbp'],verbose=False)\n",
    "                else:\n",
    "                    f,Xa = LMRlite.Kalman_ESRF(cfg_new,vY[:,kk],vR,vYe,ad[ii]['Xbp'],X=ad[ii]['X'],vYe_coords=vYe_coords,verbose=False)\n",
    "\n",
    "                xam = Xa.mean(axis=1)\n",
    "                Xap = np.subtract(Xa,xam[:,None])\n",
    "                #import pdb;  pdb.set_trace()\n",
    "                fp[:,kk]    = f\n",
    "\n",
    "            # Store information in a dictionary for this prior-truth pair\n",
    "            c = {}\n",
    "            c['locrad']     = LOCRAD\n",
    "            c['snr']        = SNR\n",
    "            c['prior_name'] = ad[ii]['name']\n",
    "            c['truth_name'] = ad[jj]['name']\n",
    "            c['pind']       = ii\n",
    "            c['tind']       = jj\n",
    "            c['recon']      = fp\n",
    "            c['rmse']       = np.mean((ad[jj]['Xbp'][:,:NENS]-fp)**2,1)**.5\n",
    "\n",
    "            # Concatenate the dictionary to a list corresponding to all prior-truth pairs \n",
    "            # for the choices of LOCRAD and SNR\n",
    "            cdd.append(c)\n",
    "\n",
    "    # Save all prior-truth pairs for these choices of LOCRAD and SNR\n",
    "    print('saving for LOCRAD = '+ str(LOCRAD) + ' and SNR = '+ str(SNR))\n",
    "    np.save('/Users/dan/Desktop/Nullspace/pt_out/PAGES2k_locrad_' + str(LOCRAD)+ '_snr_' + str(SNR)+'_300_redo_for_ad',cdd)\n",
    "    np.save('/Users/dan/Desktop/Nullspace/pt_out/PAGES2k_locrad_' + str(LOCRAD)+ '_snr_' + str(SNR)+'_300_redo_for_ad_ad',ad)\n",
    "    print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking configuration ... \n",
      "OK!\n",
      "Checking configuration ... \n",
      "OK!\n",
      "Checking configuration ... \n",
      "OK!\n",
      "saving for LOCRAD = 0.0 and SNR = 0.4\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run in parallel\n",
    "LOCRADs = [0.0]#,25000.0,10000.0,5000.0,2000.0]\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "nj = len(LOCRADs)\n",
    "Parallel(n_jobs=nj)(delayed(process_input)(LOCRADs[i]) for i in np.arange(nj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
